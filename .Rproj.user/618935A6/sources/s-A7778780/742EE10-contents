---
title: "Personnalité"
author: "cb"
date: "19/10/2021"
output: html_document
---

## Objectifs



## les packages utilisés

On utilise principalement les ressources de `quanteda` et l'analyse factorielle des correspondances avec `Factominer`

```{r setup}
knitr::opts_chunk$set(echo = TRUE,include=TRUE, warning=FALSE, message=FALSE)
library(tidyverse)
library(readr)

library(lubridate)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)

library(ggwordcloud)
library(ggmosaic)
library(rcompanion)

library(cowplot)
library ("FactoMineR")
library(factoextra)
library(seededlda)
library(gam)
```



## lecture et recodage des données

```{r 02}
perso <- read_csv("perso.csv", locale = locale())%>% 
  rename(personnalite=4,nps=5)

perso$connaissance2[perso$connaissance=="J'en ai une bonne connaissance même je ne l'achète jamais"] <-"Achète pas"
perso$connaissance2[perso$connaissance=="Je l'achète ou la consomme occasionnellement"] <- "occasionnellement"
perso$connaissance2[perso$connaissance=="Je l'achète ou la consomme régulièrement"] <-" regulièrement"
perso$connaissance2[perso$connaissance=="Je la connais car je l'achetais ou la consommais régulièrement"] <-" Avant"
perso$connaissance2[perso$connaissance=="Je la connais de manière superficielle"] <-" superficiellement"



#palette de couleur
col<-c("firebrick","Gold3","Darkgreen")


theme_set(theme_minimal())
```

## La distribution du nps

générale

```{r 03}

perso<-perso %>%
  mutate(NPS=ifelse(nps<7, "Détracteurs", 
                    ifelse(nps>6 & nps<9,"Passifs", "Promoteurs")),
         p=ifelse(NPS=="Promoteurs", 1, 0),
         d=ifelse(NPS=="Détracteurs", 1, 0))


g<-ggplot(perso, aes(x=nps))+
  geom_histogram(binwidth = 1, aes(fill=NPS))+
  labs( title= " Distribution des scores NPS", 
        subtitle = "", 
        caption = "n=", 
        y = "Fréquence")+ 
  scale_fill_manual(values=col)
g  
ggsave("NPS1.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")

```

```{r 03}

g<-ggplot(perso, aes(x=Marque, y= nps))+
  geom_boxplot()+
  labs( title= " Distribution des scores NPS par Marque", 
        subtitle = "", 
        caption = "n=", 
        y = "NPS")+ 
  scale_fill_manual(values=col) + coord_flip()
g  

ggsave("NPS2.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")

```


Comme nous allons traiter du texte et que celui n'est présent que dans une partie des réponses, on peut se demander s'il y a un biais. 

par marque

## Connaissance et expérience



```{r 02b}

#library(ggmosaic)
#library(rcompanion)
#recodons les répondants


t<-table(perso$NPS,perso$Marque)

t
chi2<-chisq.test(t)
chi<-round(chi2$statistic,2)
p<-round(chi2$p.value,3)
V<-cramerV(t, digit=3)

g1 <- ggplot(data = perso) +
  geom_mosaic(aes(x=product(NPS ,Marque), fill = NPS))+  
  theme(axis.text.x = element_text(angle = 45, hjust = -0.1, vjust = -0.2))+ 
  theme(legend.position = "none")+
  labs(title="", 
       subtitle=paste0("chi2 =",chi, " p = ", p, " - V : ", V))+    
  scale_fill_manual(values=col) 

g1
```




## Corpus

On utilise quanteda . 

```{r 04}
# 1 définir le corpus

corpus<-corpus(perso,text_field ="personnalite")


# 2 tokeniser le corpus

toks <- tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE) %>% 
    tokens_remove(pattern = stopwords("fr")) %>% 
  tokens_tolower()%>%
   tokens_remove(pattern="botanic.*")%>%
  tokens_group(groups=Marque)


# 3 construire le dfm 

dfm <- dfm(toks) %>%   
  dfm_trim(min_termfreq = 1, verbose = FALSE)

foo<-as.data.frame(dfm)

# 4 afficher le wordcloud

textplot_wordcloud(dfm,comparison = TRUE, color = col)

```

## Un autre wordcloud

Une autre méthode avec meilleure préparation du texte. et surtout de la collocation


pour le détail voir : https://quanteda.io/reference/textstat_collocations.html


```{r 05}

toks <- tokens(corpus, remove_punct = TRUE) %>% 
  tokens_tolower()%>%
  tokens_group(groups = NPS)

coloc <- textstat_collocations(toks, size = 2:4, min_count = 10) %>% filter(z>15)

head(coloc, 20)


toks2 <- tokens_compound(toks, pattern = coloc) %>%     
  tokens_remove(pattern = stopwords("fr") )



dfm <-toks2 %>%
    tokens_group(groups = NPS)%>% 
  dfm()

stat<- dfm %>% 
  textstat_frequency(n = 30,  groups = NPS)

g_b<-ggplot(stat, aes(label = feature)) +
  geom_text_wordcloud(aes(size=log(frequency), color=group)) +
  theme_minimal()+
  facet_wrap(vars(group))+
  scale_color_manual(values=col)+ 
  labs(title="Nuage des 50 mots les plus fréquents(Par groupes",
       caption = "La taille des mots est proportionnelle au log de leurs fréquences")
g_b
ggsave("NPS3.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")

```

## Réseau sémantique


sur la base de 

https://kateto.net/networks-r-igraph/


```{r 05b}

toks2 <- tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE) %>% 
    tokens_remove(pattern = stopwords("fr")) %>% 
  tokens_tolower()%>%
   tokens_remove(pattern="botanic.*", valuetype = "regex") 


fcmat <- fcm(toks2, context = "window",window = 5L, tri = FALSE)

feat <- names(topfeatures(fcmat, 500))

set.seed(100)
fcm_select(fcmat, pattern = feat) %>%
    textplot_network(min_freq = 3,edge_color = "grey50",
  edge_alpha = 0.2,vertex_labelsize=3)
```
    
    
## Pour comparer les segments, le Keyness index est particulièrement utile

Il est calculé en comparant un groupe cible à l'ensemble des autres groupes par une mesure d'association : un chi², ou un point.wise correlation.

```{r 06}

# Create a dfm per group
dfm <-toks2 %>%
    tokens_group(groups = NPS) %>% 
  dfm()


# Calculate keyness and determine "Promoteurs" as target group againts all other categories
result_keyness <- textstat_keyness(dfm, target = "Promoteurs")

# Plot estimated word keyness
g1<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE, 
                     show_reference = FALSE,   color = c("Darkgreen", "gray"))+
  xlim(-20,80) + 
  labs(x=NULL)


result_keyness <- textstat_keyness(dfm, target = "Détracteurs" )
g2<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE,   
                     show_reference = FALSE,   color = c("firebrick", "gray"))+
  xlim(0,80)+ 
  labs(x=NULL)


result_keyness <- textstat_keyness(dfm, target = "Passifs")
g3<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE,   show_reference = FALSE,    color = c("gold2", "gray"))+xlim(0,80)+ labs(x=NULL)



p<- plot_grid(g2, g3 ,g1,  labels = c('Détracteurs', 'Passifs', 'Promoteurs'), label_size = 12, ncol=3)
title <- ggdraw() + draw_label("NPS : Les raisons qui conduisent à la recommandation (keyness)", fontface='bold')
note <- ggdraw()+ draw_text("Les valeurs représentent le keyness des termes.\nIl mesure leur caractère distinctif par une statistique du chi²", size=8,x = 0.5, y = 0.5)


plot_grid(title, p,note, ncol=1, rel_heights=c(0.1, 1)) # rel_heights values control title margins


ggsave("NPS4.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
#  pour une comparaison deux à deux
#   pres_corpus <- corpus_subset(corpus, NPS %in% c("Détracteurs", "Promoteurs"))


#plot_grid(g ,p,d, labels = c("", "", "", ""), label_size = 12, ncol = 2, nrow = )

#ggsave("NPS5.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")


```

## Un peu de topic analysis


La structure du modèle

!["modèle LDA"](Schematic-of-LDA-algorithm.png)


source : https://arxiv.org/pdf/1003.0783.pdf

preparation des données

```{r 07}
# pre processing : 

corpus<-corpus(perso,text_field ="personnalite")

toks <- tokens(corpus, remove_punct = TRUE)

cols <- textstat_collocations(toks, size = 2:4, min_count = 20) %>% filter(z>20)

toks2 <- tokens_compound(toks, pattern = cols) %>%     
  tokens_remove(pattern = stopwords("fr") )

dfm<-dfm(toks2)
dfm<- dfm_trim(dfm, min_termfreq = 1, min_docfreq = 1)


```

estimation du modèle


```{r 07b, eval=FALSE}

library(seededlda)
t1=Sys.time()

set.seed(123)
tmod_lda <- textmodel_lda(dfm, k = 5)

t2=Sys.time()
t=t2-t1
t

#lister les mots les plus associés
seededlda::terms(tmod_lda,5)

perso$topic <- seededlda::topics(tmod_lda)

#saveRDS(tmod_lda,"lda.rds")

#saveRDS(dfm,"topic.rds")
```



```{r 07c, eval=FALSE}

library("ldatuning")
library("topicmodels")
raw.sum=apply(dfm,1,FUN=sum) #sum by raw each raw of the table
dfm=dfm[raw.sum!=0,]


result <- FindTopicsNumber(
  dfm,
  topics = seq(from = 2, to = 10, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)
FindTopicsNumber_plot(result)

```

On sauvegarde les résultats pour se prémunir de l'instabilité des solutions ( en dépit du set seed) dans un format rds

## Analyse des topics


```{r 10}


phi<-as.data.frame(tmod_lda$phi)
phi$topic<-row.names(phi)
phi<-phi %>%
  gather(variable, value, -topic) %>% 
  group_by(topic)%>%
  mutate(rank=row_number(desc(value))) %>% filter(rank<20)

ggplot(phi, aes(x=topic, y=rank,label = variable)) + 
  scale_y_reverse() +
  geom_text(aes(color=topic,size=1000*value))+
  theme_minimal()+
  scale_color_hue()+
  guides(color="none",size="none")


```


## Une bonne vieille analyse des correspondances pour associer les segments aux thèmes du discours

pour plus de détails sur l'analyse des correspondances regarder par exemple [Anne B Dufour](https://pbil.univ-lyon1.fr/R/pdf/add2.pdf).



```{r 08}
#un peu de recodage
table(perso$topic)

#on recode pour une meilleure lecture
#dfm$topic2[dfm$topic=="topic1"]<-"Magasin"
#dfm$topic2[dfm$topic=="topic2"]<-"Achat"
#dfm$topic2[dfm$topic=="topic3"]<-"Cartedefid"
#dfm$topic2[dfm$topic=="topic4"]<-"bioplantes"
#dfm$topic2[dfm$topic=="topic5"]<-"Personnel"
#dfm$topic2[dfm$topic=="topic6"]<-"prix"
#dfm$topic2[dfm$topic=="topic7"]<-"Caisse"

#table(dfm$topic2)

#le tableau croisé

ca<- table(perso$topic, perso$NPS)
prop.table(ca, 2)

#library ("FactoMineR")
#library(factoextra)
res.ca <- CA (ca, graph = FALSE)
fviz_ca_biplot (res.ca, repel = TRUE)


```


## Régression gam pour mesurer les non-linéarités

elles sont non linéaires donc adaptées à détecter une structure type [kano](https://fr.wikipedia.org/wiki/Mod%C3%A8le_de_Kano) (pour certais attributs l'absence conduit à l'insatisfaction, mais leur présence ne conduit pas à plus d'information, et pour d'autres leur absence ne conduit pas à l'insatisfaction alors que leur présence renforce la satisfaction)

https://www.researchgate.net/publication/228434290_The_Kano_model-A_review_of_its_application_in_marketing_research_from_1984-2006/figures

Dans l'idée celà correspond à la théorie bifactorielle de herzberg.

Avec cette application on mesure la présence dans le discours d'un attribut. Ce degré de présence est simplement le paramètre theta du topic k pour texte i. Ce dont les consommateurs parlent peut a priori être aussi bien associés à une bonne ou une mauvaise opinion. Si la corrélation (linéaire est positive) c'est qu'on a affaire à un argument attractif qui ajoute aux attributs de base qui restent transparent pour le locuteur. Si elle est négative c'est qu'on à affaire à un une besoin de base, plus il pose problème et plus on en parle. D'autres attributs peuvent se caractériser par une courbe en U, il sont associé positivement quand on en parle modéremment, ou en compagnie d'un autre attribut. On observe pas la configuration d'un U inversé.

inspiré de https://rpubs.com/apierucci/lm-gam


```{r 09}


theta<-tmod_lda$theta

perso<-cbind(perso,theta)

#on recode pour une meilleure lecture
#topic <- topic %>% 
#  rename(
#Caisse = topic1,
#Magasin = topic2,
#Bioplantes= topic3,
#Personnel=topic4,
#Cartedefid= topic5,
#Achat= topic6,
#Prix =topic7)

fit<-lm(nps~topic1+topic2+topic3+topic4, data =topic)
summary(fit)

library(gam)
mod1 <- gam(nps ~ s(topic1) +s(topic2)+s(topic3)+s(topic4), data = topic, family = gaussian)

summary(mod1)

par(mfrow = c(2, 3))
termplot(mod1,rug = TRUE, se = TRUE,  terms = c("s(topic1)", "s(topic2)", "s(topic3)", "s(topic4)"))

```

## Segmenter


```{r 09}

df_clus<- perso %>% 
  select(topic1,topic2,topic3,topic4,topic5) %>%drop_na()

dist<-dist(df_clus)



fit <-hclust(dist, method="ward")

#afficher
plot(fit)


groups <- as.data.frame(cutree(fit, k=4)) 

df_clus<- cbind(df_clus, groups)  %>% rename(segment=6)


foo<- df_clus %>%
  gather(variable, value , -segment) %>%
  group_by(segment, variable) %>% 
  summarise(value=mean(value))# cut tree into 5 clusters

g1<- ggplot(foo, aes(x=segment,y=value, group=variable))+
  geom_bar(stat="identity", aes(fill= variable))

table(df_clus$segment)
g2<-ggplot(df_clus, aes(x=segment))+geom_bar()
g2

plot_grid(g1, g2,  nrow=2)

df_clus2<-cbind(perso,groups)%>%
  rename(segment=16)%>% 
  group_by(segment)%>%
  summarise(nps=mean(nps, na.rm=TRUE))



ggplot(df_clus2, aes(x=segment,y=nps))+geom_bar(stat="identity")


```
## Pos et dépendances syntaxiques


```{r 10}
library(cleanNLP)
cnlp_init_udpipe(model_name = "french")
annotate<-cnlp_annotate(perso, text_name = "personnalite",doc_name = "id", verbose = 1000)

obj<-annotate$token
 
 

```

## Analyse de réseau sémantique restreinte aux adjectifs


```{r 11, fig.width==10}
perso$doc_id<-as.numeric(rownames(perso))

res1 <-obj %>%
  filter(relation == "amod") %>% #selection
  full_join(perso) %>%  #enrichissement
  select(Marque, lemma)%>% mutate(n=1)%>% #frequence des mots par marques
  group_by(Marque, lemma)%>%
  summarise(n=sum(n)) %>% 
  drop_na()

#res1[is.na(res1)] <- 0


lemma<-res1 %>% group_by(lemma)%>%summarise(n=sum(n))
Marque<-res1 %>% group_by(Marque)%>%summarise(n=sum(n))



#library
library(igraph)

#graphe bipartite
Edge<-res1
Edge<-subset(Edge, n>0)   #ne garder que ceux qui sont effectifs

#definition du graphe

g <- graph_from_data_frame(Edge, directed=FALSE, vertices=NULL)

#définir les paramètres
layout <- layout_with_mds(g, dim=2)
V(g)$type <- bipartite.mapping(g)$type

col = ifelse( V(g)$type, "black", "Red") # assign color by node type
shape = ifelse(V(g)$type, "circle", "square") # assign shape by node type

size=ifelse(V(g)$type, Marque$n, lemma$n)


#tracer le graphe
plot(g,
     vertex.label.color = col,
     vertex.shape=shape,
     vertex.label.cex=0.7, 
     vertex.label.family="TT Arial", 
     vertex.size=c(0),
     vertex.label.cex=size,
     edge.arrow.size=0,
     edge.width=1*(E(g)$n),
     edge.curved=0.5
     )


# Set a seed if you want reproducible results
set.seed(42)




```


## Analyse de réseau sémantique restreinte aux adjectifs

On utilise igraph ( le manuel de début est ici https://kateto.net/networks-r-igraph/)


```{r 11, fig.width=12}
perso$doc_id<-as.numeric(rownames(perso))

res1 <-obj %>%
  filter(relation == "amod") %>% #selection
  full_join(perso) %>%  #enrichissement
  select(Marque, lemma)%>% mutate(n=1)%>% #frequence des mots par marques
  group_by(Marque, lemma)%>%
  summarise(n=sum(n)) %>% 
  drop_na()

#res1[is.na(res1)] <- 0

lemma<-res1 %>% group_by(lemma)%>%summarise(n=sum(n))%>%rename(lemma=lemma)
Marque<-res1 %>% group_by(Marque)%>%summarise(n=sum(n))%>%rename(lemma=Marque) # à verif
lemma2<-rbind(lemma, Marque)
Marque2<-df %>% group_by(Marque)%>%summarise(nps=mean(nps))

library(igraph)
fine <- 5
palette <- colorRampPalette(c('red','Orange','green2'), alpha=TRUE)

#graphe bipartite
Edge<-res1
Edge<-subset(Edge, n>0)   #ne garder que ceux qui sont effectifs

#definition du graphe

g <- graph_from_data_frame(Edge, directed=FALSE, vertices=NULL)

#définir les paramètres du graph
layout <- layout_with_mds(g, dim=2) #projection dans le plan

V(g)$type <- bipartite.mapping(g)$type #prendre en compte les 2 catégorie d'obkets ( marques et termes)
V(g)$color <- palette(fine) [as.numeric(cut(Marque2$nps,breaks=fine))]# colour_values(Marque2$nps,palette = "palette")


col2 = ifelse( V(g)$type, "grey20", "black") # assign color by node type


shape1 = ifelse(V(g)$type, "square", "circle") # assign shape by node type
siz1=ifelse(V(g)$type, 0, Marque$n/2)
siz2=ifelse(V(g)$type, log(lemma$n)/4, 0)

library(extrafont)
font_import()

#tracer le graphe
plot(g,
     vertex.label.color = col2,
     vertex.shape=shape1,
     vertex.size=siz1,
     vertex.label.cex=siz2,
     vertex.label.family="Helvetica",
     edge.arrow.size=0,
     edge.width=1*(E(g)$n),
     edge.curved=0.5,
     vertex.color=V(g)$color)


```

