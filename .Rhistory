t=t1-t2)%>%
group_by(id)%>%
summarise(nps=max(nps, na.rm=TRUE),
satisfaction=max(satisfaction, na.rm=TRUE),
intention=max(intention, na.rm=TRUE),
explication=last(explication),
NbPassageKS=last(NbPassageKS),
CaTicket=last(CaTicket),
t=last(t))
foo$CaTicket<-as.numeric(foo$CaTicket)
foo$nps<-as.numeric(foo$nps)
foo$satisfaction<-as.numeric(foo$satisfaction)
foo$intention<-as.numeric(foo$intention)
table(foo$t)
foo1<-foo %>%
mutate(NPS=ifelse(nps<7, "Détracteurs",
ifelse(nps>6 & nps<9,"Passifs", "Promoteurs"))) %>%
mutate(p=ifelse(NPS=="Promoteurs", 1, 0),
d=ifelse(NPS=="Détracteurs", 1, 0))
d<- mean(foo1$d, na.rm=TRUE)
p<-mean(foo1$p, na.rm=TRUE)
score_nps<- round((p-d)*100,1)
g<-ggplot(foo1, aes(x=nps))+
geom_histogram(binwidth = 1,aes(fill=NPS))+
theme_bw()+
labs( title= " Distribution des scores NPS", subtitle = paste0("Score NPS = ", score_nps), caption = "n=13954", y = "Fréquence")+ scale_fill_manual(values=col)+
scale_x_discrete(name="Note NPS", breaks=c("1","2","3","4","5","6","7", "8", "9", 10),
limits=c("1","2","3","4","5","6","7", "8", "9", 10))
g
ggsave("NPS1.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
foo2<-foo%>%select(2,3,4,6,CaTicket,t) %>% drop_na()
r<- round(cor(foo2),3)
library(ggcorrplot)
ggcorrplot(r, hc.order = TRUE, type = "lower",
outline.col = "white",
colors = c("#6D9EC1", "white", "#E46726"),
lab=TRUE)
library(GGally)
ggpairs(foo2, lower = list(continuous = "smooth_loess", combo = ggally_dot_no_facet),title="correlogram with ggpairs()")
fit<- lm(nps~NbPassageKS+CaTicket+t, foo)
summary(fit)
corpus<-corpus(foo1,text_field ="explication")
toks <- tokens(corpus, remove_punct = FALSE) %>%
tokens_remove(pattern = stopwords("fr"))%>%
tokens_remove(pattern="Botanic.*") %>%
tokens_group(groups = NPS)
dfm <- dfm(toks) %>%
dfm_trim(min_termfreq = 30, verbose = FALSE)
textplot_wordcloud(dfm,comparison = TRUE, color = col)
toks <- tokens(corpus, remove_punct = TRUE) %>%
tokens_group(groups = NPS)
cols <- textstat_collocations(toks, size = 2:4, min_count = 5) %>%filter(z>15)
cols
toks2 <- tokens_compound(toks, pattern = cols) %>%
tokens_remove(pattern = stopwords("fr") )
dfm <-toks2 %>%
tokens_group(groups = NPS)%>%
dfm()
stat<- dfm %>%
textstat_frequency(n = 50,  groups = NPS)
g_b<-ggplot(stat, aes(label = feature)) +
geom_text_wordcloud(aes(size=log(frequency), color=group)) +
theme_minimal()+
facet_wrap(vars(group))+scale_color_manual(values=col)+
labs(title="Nuage des 50 mots les plus fréquents(Par groupes",
caption = "La taille des mots est proportionnelle au log de leurs fréquences")
g_b
ggsave("NPS3.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
# Create a dfm per group
dfm <-toks2 %>%
tokens_group(groups = NPS)%>%
dfm()
# Calculate keyness and determine "Promoteurs" as target group againts all other categories
result_keyness <- textstat_keyness(dfm, target = "Promoteurs") %>% filter (n_target>20)
# Plot estimated word keyness
g1<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE, show_reference = FALSE,   color = c("Darkgreen", "gray"))+
xlim(0,80) +
labs(x=NULL)
result_keyness <- textstat_keyness(dfm, target = "Détracteurs" )
g2<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE,
show_reference = FALSE,   color = c("firebrick", "gray"))+
xlim(0,80)+
labs(x=NULL)
result_keyness <- textstat_keyness(dfm, target = "Passifs")
g3<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE,   show_reference = FALSE,    color = c("gold2", "gray"))+xlim(0,80)+ labs(x=NULL)
p<- plot_grid(g2, g3 ,g1,  labels = c('Détracteurs', 'Passifs', 'Promoteurs'), label_size = 12, ncol=3)
title <- ggdraw() + draw_label("NPS : Les raisons qui conduisent à la recommandation (keyness)", fontface='bold')
note <- ggdraw()+ draw_text("Les valeurs représentent le keyness des termes.\nIl mesure leur caractère distinctif par une statistique du chi²", size=8,x = 0.5, y = 0.5)
plot_grid(title, p,note, ncol=1, rel_heights=c(0.1, 1)) # rel_heights values control title margins
ggsave("NPS4.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
#  pour une comparaison deux à deux
#   pres_corpus <- corpus_subset(corpus, NPS %in% c("Détracteurs", "Promoteurs"))
plot_grid(g ,g_b,p,d, labels = c("", "", "", ""), label_size = 12,
ncol = 2, nrow = 2)
ggsave("NPS5.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
# pre processing :
toks <- tokens(corpus, remove_punct = TRUE)
cols <- textstat_collocations(toks, size = 2:4, min_count = 5) %>%filter(z>20)
toks2 <- tokens_compound(toks, pattern = cols) %>%
tokens_remove(pattern = stopwords("fr") )
dfm<-dfm(toks2)
library(seededlda)
set.seed(007)
tmod_lda <- textmodel_lda(dfm, k = 8)
#lister les mots les plus associés
terms(tmod_lda, 25)
#un peu de recodage
dfm$topic <- topics(tmod_lda)
table(dfm$topic)
#on recode pour une meilleure lecture
dfm$topic2[dfm$topic=="topic1"]<-"conseil"
dfm$topic2[dfm$topic=="topic2"]<-"Carte de fid"
dfm$topic2[dfm$topic=="topic3"]<-"Caisse"
dfm$topic2[dfm$topic=="topic4"]<-"c'est bien continuez"
dfm$topic2[dfm$topic=="topic5"]<-"acheter"
dfm$topic2[dfm$topic=="topic6"]<-"Compétence amabilité"
dfm$topic2[dfm$topic=="topic7"]<-"prix"
dfm$topic2[dfm$topic=="topic8"]<-"choix des plantes"
table(dfm$topic2)
#le tableau croisé
ca<- table(dfm$topic2, dfm$NPS)
prop.table(ca, 2)
#library ("FactoMineR")
#library(factoextra)
res.ca <- CA (ca, graph = FALSE)
fviz_ca_biplot (res.ca, repel = TRUE)
#un peu de recodage
dfm$topic <- topics(tmod_lda)
table(dfm$topic)
#on recode pour une meilleure lecture
dfm$topic2[dfm$topic=="topic1"]<-"conseil"
dfm$topic2[dfm$topic=="topic2"]<-"Carte de fid"
dfm$topic2[dfm$topic=="topic3"]<-"Bio"
dfm$topic2[dfm$topic=="topic4"]<-"acheter"
dfm$topic2[dfm$topic=="topic5"]<-"c'est tout bien"
dfm$topic2[dfm$topic=="topic6"]<-"Compétence amabilité"
dfm$topic2[dfm$topic=="topic7"]<-"prix"
dfm$topic2[dfm$topic=="topic8"]<-"choix des plantes"
table(dfm$topic2)
#le tableau croisé
ca<- table(dfm$topic2, dfm$NPS)
prop.table(ca, 2)
#library ("FactoMineR")
#library(factoextra)
res.ca <- CA (ca, graph = FALSE)
fviz_ca_biplot (res.ca, repel = TRUE)
knitr::opts_chunk$set(echo = TRUE,include=TRUE, warning=FALSE, message=FALSE)
library(tidyverse)
library(readxl)
library(lubridate)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(ggwordcloud)
library(tidytext)
library(cowplot)
library ("FactoMineR")
library(factoextra)
df<-readRDS("Enqueteclient.rds")
#palette de couleur
col<-c("firebrick","Gold3","Darkgreen")
write.csv(foo,"nps.csv")
knitr::opts_chunk$set(echo = TRUE,include=TRUE, warning=FALSE, message=FALSE)
library(tidyverse)
library(readxl)
library(lubridate)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(ggwordcloud)
library(tidytext)
library(cowplot)
library ("FactoMineR")
library(factoextra)
df<-readRDS("nps.rds")
library(readr)
nps <- read_csv("nps.csv", locale = locale(encoding = "WINDOWS-1252"))
View(nps)
knitr::opts_chunk$set(echo = TRUE,include=TRUE, warning=FALSE, message=FALSE)
library(tidyverse)
library(readxl)
library(lubridate)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(ggwordcloud)
library(tidytext)
library(cowplot)
library ("FactoMineR")
library(factoextra)
df<-read_csv("nps.csv", locale = locale(encoding = "WINDOWS-1252"))
#palette de couleur
col<-c("firebrick","Gold3","Darkgreen")
df<-read_csv("nps.csv", locale = locale(encoding = "WINDOWS-1252"))
foo1<-foo %>%
mutate(NPS=ifelse(nps<7, "Détracteurs",
ifelse(nps>6 & nps<9,"Passifs", "Promoteurs"))) %>%
mutate(p=ifelse(NPS=="Promoteurs", 1, 0),
d=ifelse(NPS=="Détracteurs", 1, 0))
d<- mean(foo1$d, na.rm=TRUE)
p<-mean(foo1$p, na.rm=TRUE)
score_nps<- round((p-d)*100,1)
g<-ggplot(foo1, aes(x=nps))+
geom_histogram(binwidth = 1,aes(fill=NPS))+
theme_bw()+
labs( title= " Distribution des scores NPS", subtitle = paste0("Score NPS = ", score_nps), caption = "n=13954", y = "Fréquence")+ scale_fill_manual(values=col)+
scale_x_discrete(name="Note NPS", breaks=c("1","2","3","4","5","6","7", "8", "9", 10),
limits=c("1","2","3","4","5","6","7", "8", "9", 10))
g
ggsave("NPS1.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
foo1<-df %>%
mutate(NPS=ifelse(nps<7, "Détracteurs",
ifelse(nps>6 & nps<9,"Passifs", "Promoteurs"))) %>%
mutate(p=ifelse(NPS=="Promoteurs", 1, 0),
d=ifelse(NPS=="Détracteurs", 1, 0))
d<- mean(foo1$d, na.rm=TRUE)
p<-mean(foo1$p, na.rm=TRUE)
score_nps<- round((p-d)*100,1)
g<-ggplot(foo1, aes(x=nps))+
geom_histogram(binwidth = 1,aes(fill=NPS))+
theme_bw()+
labs( title= " Distribution des scores NPS", subtitle = paste0("Score NPS = ", score_nps), caption = "n=13954", y = "Fréquence")+ scale_fill_manual(values=col)+
scale_x_discrete(name="Note NPS", breaks=c("1","2","3","4","5","6","7", "8", "9", 10),
limits=c("1","2","3","4","5","6","7", "8", "9", 10))
g
ggsave("NPS1.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
foo1 <- foo1 %>% mutate(reponse=ifelse(is.na(explication), "Pas de réponse", "Réponse"))
foo1<-df %>%
mutate(NPS=ifelse(nps<7, "Détracteurs",
ifelse(nps>6 & nps<9,"Passifs", "Promoteurs"))) %>%
mutate(p=ifelse(NPS=="Promoteurs", 1, 0),
d=ifelse(NPS=="Détracteurs", 1, 0))
#calcul du score NPS
d<- mean(foo1$d, na.rm=TRUE)
p<-mean(foo1$p, na.rm=TRUE)
score_nps<- round((p-d)*100,1)
g<-ggplot(foo1, aes(x=nps))+
geom_histogram(binwidth = 1,aes(fill=NPS))+
theme_bw()+
labs( title= " Distribution des scores NPS", subtitle = paste0("Score NPS = ", score_nps), caption = "n=13954", y = "Fréquence")+ scale_fill_manual(values=col)+
scale_x_discrete(name="Note NPS", breaks=c("1","2","3","4","5","6","7", "8", "9", 10),
limits=c("1","2","3","4","5","6","7", "8", "9", 10))
g
ggsave("NPS1.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
t<-table(foo1$NPS,foo1$reponse)
table(foo1$reponse)
foo1 <- foo1 %>% mutate(reponse==ifelse(is.na(explication), "Pas de réponse", "Réponse"))
foo1 <- foo1 %>% mutate(reponse=ifelse(is.na(explication), "Pas de réponse", "Réponse"))
table(foo1$reponse)
t<-table(foo1$NPS,foo1$reponse)
chi2<-chisq.test(t)
chi<-round(chi2$statistic,2)
p<-round(chi2$p.value,3)
V<-cramerV(t, digit=3)
#library(ggmosaic)
library(companion)
#library(ggmosaic)
library(rcompanion)
V<-cramerV(t, digit=3)
g1 <- ggplot(data = foo1) +
geom_mosaic(aes(x=product( NPS ,reponse), fill = NPS))+
theme(axis.text.x = element_text(angle = 45, hjust = -0.1, vjust = -0.2))+
theme(legend.position = "none")+
labs(title="Statut vaccinal \npar genre",
subtitle=paste0("chi2 =",chi, " p = ", p, " - V : ", V))+
scale_fill_brewer(palette = "RdYlGn", direction = -1)
library(ggmosaic)
g1 <- ggplot(data = foo1) +
geom_mosaic(aes(x=product( NPS ,reponse), fill = NPS))+
theme(axis.text.x = element_text(angle = 45, hjust = -0.1, vjust = -0.2))+
theme(legend.position = "none")+
labs(title="Statut vaccinal \npar genre",
subtitle=paste0("chi2 =",chi, " p = ", p, " - V : ", V))+
scale_fill_brewer(palette = "RdYlGn", direction = -1)
g1
g1 <- ggplot(data = foo1) +
geom_mosaic(aes(x=product( NPS ,reponse), fill = NPS))+
theme(axis.text.x = element_text(angle = 45, hjust = -0.1, vjust = -0.2))+
theme(legend.position = "none")+
labs(title="Un biais négatif de réponse",
subtitle=paste0("chi2 =",chi, " p = ", p, " - V : ", V))+
scale_fill_brewer(palette = "RdYlGn", direction = -1)
g1
theme_set(theme_minimal())
foo1<-df %>%
mutate(NPS=ifelse(nps<7, "Détracteurs",
ifelse(nps>6 & nps<9,"Passifs", "Promoteurs"))) %>%
mutate(p=ifelse(NPS=="Promoteurs", 1, 0),
d=ifelse(NPS=="Détracteurs", 1, 0))
#calcul du score NPS
d<- mean(foo1$d, na.rm=TRUE)
p<-mean(foo1$p, na.rm=TRUE)
score_nps<- round((p-d)*100,1)
g<-ggplot(foo1, aes(x=nps))+
geom_histogram(binwidth = 1,aes(fill=NPS))+
theme_bw()+
labs( title= " Distribution des scores NPS", subtitle = paste0("Score NPS = ", score_nps), caption = "n=13954", y = "Fréquence")+ scale_fill_manual(values=col)+
scale_x_discrete(name="Note NPS", breaks=c("1","2","3","4","5","6","7", "8", "9", 10),
limits=c("1","2","3","4","5","6","7", "8", "9", 10))
g
ggsave("NPS1.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
library(ggmosaic)
#library(rcompanion)
#recodons les répondants
foo1 <- foo1 %>% mutate(reponse=ifelse(is.na(explication), "Pas de réponse", "Réponse"))
table(foo1$reponse)
t<-table(foo1$NPS,foo1$reponse)
chi2<-chisq.test(t)
chi<-round(chi2$statistic,2)
p<-round(chi2$p.value,3)
V<-cramerV(t, digit=3)
g1 <- ggplot(data = foo1) +
geom_mosaic(aes(x=product( NPS ,reponse), fill = NPS))+
theme(axis.text.x = element_text(angle = 45, hjust = -0.1, vjust = -0.2))+
theme(legend.position = "none")+
labs(title="Un biais négatif de réponse",
subtitle=paste0("chi2 =",chi, " p = ", p, " - V : ", V))+
scale_fill_brewer(palette = "RdYlGn", direction = -1)
g1
g1 <- ggplot(data = foo1) +
geom_mosaic(aes(x=product( NPS ,reponse), fill = NPS))+
theme(axis.text.x = element_text(angle = 45, hjust = -0.1, vjust = -0.2))+
theme(legend.position = "none")+
labs(title="Un biais négatif de réponse",
subtitle=paste0("chi2 =",chi, " p = ", p, " - V : ", V))+
scale_fill_manual(values=col)
g1
foo2<-foo1 %>% select(3,4,5,6,7,8) %>% drop_na()
r<- round(cor(foo2),3)
foo2<-foo1 %>% select(3,4,5,7,8) %>% drop_na()
r<- round(cor(foo2),3)
library(ggcorrplot)
ggcorrplot(r, hc.order = TRUE, type = "lower",
outline.col = "white",
colors = c("#6D9EC1", "white", "#E46726"),
lab=TRUE)
foo2<-foo1 %>% select(3,4,5,7,8,9) %>% drop_na()
r<- round(cor(foo2),3)
library(ggcorrplot)
ggcorrplot(r, hc.order = TRUE, type = "lower",
outline.col = "white",
colors = c("#6D9EC1", "white", "#E46726"),
lab=TRUE)
fit<- lm(nps~log(NbPassageKS)+log(CaTicket)+t, foo)
fit<- lm(nps~log(NbPassageKS)+log(CaTicket)+t, foo1)
ggplot(foo1,aes(CaTicket))+geom_histogram()
ggplot(foo1,aes(CaTicket))+geom_histogram(binwidth = 1)
foo1<- foo1%>%mutate(CaTicket=ifelse(CaTicket<0,0,CaTicket),
CaTicket_l=log10(CaTicket+1))
fit<- lm(nps~log(NbPassageKS)+CaTicket_l+t, foo1)
summary(fit)
fit<- lm(nps~log(NbPassageKS)+CaTicket+t, foo1)
summary(fit)
summary(fit)
ggplot(foo1,aes(NPS,CaTicket))+geom_point()+geom_smooth()
ggplot(foo1,aes(CaTicket, nps))+geom_point()+geom_smooth()
ggplot(foo1,aes(CaTicket, nps))+geom_point()+geom_smooth() +scale_x_log10()
ggplot(foo1,aes(NbPassageKS, nps))+geom_point()+geom_smooth() +scale_x_log10()
fit<- lm(nps~log(NbPassageKS)+CaTicket_l+t, foo1)
summary(fit)
ggplot(foo1,aes(NbPassageKS, nps))+geom_point()+geom_smooth() +scale_x_log10()
ggplot(foo1,aes(t, nps))+geom_point()+geom_smooth() +scale_x_log10()
fit<- lm(nps~log(NbPassageKS)+CaTicket_l+log(t), foo1)
fit<- lm(nps~log(NbPassageKS)+CaTicket_l+log(t+1), foo1)
summary(fit)
ggplot(foo1,aes(NbPassageKS, nps))+geom_point()+geom_smooth() +scale_x_log10()
fit<- lm(nps~log(NbPassageKS)+log(CaTicket+1)+log(t+1), foo1)
summary(fit)
library(jtools)
effect_plot(fit, pred=CaTicket)
effect_plot(fit, pred=CaTicket)+scale_x_log10()
effect_plot(fit, pred=NbPassageKS)+scale_x_log10()
ggplot(foo1,aes(CaTicket))+geom_histogram(binwidth = 1)
ggplot(foo1,aes(CaTicket, nps))+geom_point()+geom_smooth() +scale_x_log10()
ggplot(foo1,aes(NbPassageKS, nps))+geom_point()+geom_smooth() +scale_x_log10()
ggplot(foo1,aes(t, nps))+geom_point()+geom_smooth() +scale_x_log10()
foo1<- foo1%>%mutate(CaTicket=ifelse(CaTicket<0,0,CaTicket),
CaTicket_l=log10(CaTicket+1))
fit<- lm(nps~log(NbPassageKS)+log(CaTicket+1)+log(t+1), foo1)
summary(fit)
library(jtools)
effect_plot(fit, pred=CaTicket)+scale_x_log10()
effect_plot(fit, pred=NbPassageKS)+scale_x_log10()
effect_plot(fit, pred=NbPassageKS, interval = TRUE)+scale_x_log10()
effect_plot(fit, pred=NbPassageKS, interval = TRUE) #+scale_x_log10()
effect_plot(fit, pred=CaTicket, interval = TRUE)+#scale_x_log10()
effect_plot(fit, pred=NbPassageKS, interval = TRUE) #+scale_x_log10()
effect_plot(fit, pred=CaTicket, interval = TRUE)#scale_x_log10()
effect_plot(fit, pred=NbPassageKS, interval = TRUE) #+scale_x_log10()
effect_plot(fit, pred=t, interval = TRUE)#scale_x_log10()
corpus<-corpus(foo1,text_field ="explication")
toks <- tokens(corpus, remove_punct = FALSE) %>%
tokens_remove(pattern = stopwords("fr"))%>%
tokens_remove(pattern="Botanic.*") %>%
tokens_group(groups = NPS)
dfm <- dfm(toks) %>%
dfm_trim(min_termfreq = 30, verbose = FALSE)
textplot_wordcloud(dfm,comparison = TRUE, color = col)
# 1 définir le corpus
# 2 tokeniser le corpus
corpus<-corpus(foo1,text_field ="explication")
toks <- tokens(corpus, remove_punct = FALSE) %>%
tokens_remove(pattern = stopwords("fr"))%>%
tokens_remove(pattern="Botanic.*") %>%
tokens_group(groups = NPS)
# 3 construire le dfm
dfm <- dfm(toks) %>%
dfm_trim(min_termfreq = 30, verbose = FALSE)
# 4 afficher le wordcloud
textplot_wordcloud(dfm,comparison = TRUE, color = col)
# 1 définir le corpus
# 2 tokeniser le corpus
corpus<-corpus(foo1,text_field ="explication")
toks <- tokens(corpus, remove_punct = TRUE) %>%
tokens_remove(pattern = stopwords("fr"))%>%
tokens_remove(pattern="Botanic.*") %>%
tokens_group(groups = NPS)
# 3 construire le dfm
dfm <- dfm(toks) %>%
dfm_trim(min_termfreq = 30, verbose = FALSE)
# 4 afficher le wordcloud
textplot_wordcloud(dfm,comparison = TRUE, color = col)
head(coloc, 10)
coloc <- textstat_collocations(toks, size = 2:4, min_count = 5) %>% filter(z>15)
head(coloc, 10)
head(coloc, 20)
toks <- tokens(corpus, remove_punct = TRUE) %>%
tokens_group(groups = NPS)
coloc <- textstat_collocations(toks, size = 2:4, min_count = 5) %>% filter(z>15)
head(coloc, 20)
toks2 <- tokens_compound(toks, pattern = cols) %>%
tokens_remove(pattern = stopwords("fr") )
dfm <-toks2 %>%
tokens_group(groups = NPS)%>%
dfm()
stat<- dfm %>%
textstat_frequency(n = 50,  groups = NPS)
g_b<-ggplot(stat, aes(label = feature)) +
geom_text_wordcloud(aes(size=log(frequency), color=group)) +
theme_minimal()+
facet_wrap(vars(group))+scale_color_manual(values=col)+
labs(title="Nuage des 50 mots les plus fréquents(Par groupes",
caption = "La taille des mots est proportionnelle au log de leurs fréquences")
g_b
ggsave("NPS3.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
# Create a dfm per group
dfm <-toks2 %>%
tokens_group(groups = NPS)%>%
dfm()
# Calculate keyness and determine "Promoteurs" as target group againts all other categories
result_keyness <- textstat_keyness(dfm, target = "Promoteurs") %>% filter (n_target>20)
# Plot estimated word keyness
g1<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE, show_reference = FALSE,   color = c("Darkgreen", "gray"))+
xlim(0,80) +
labs(x=NULL)
result_keyness <- textstat_keyness(dfm, target = "Détracteurs" )
g2<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE,
show_reference = FALSE,   color = c("firebrick", "gray"))+
xlim(0,80)+
labs(x=NULL)
result_keyness <- textstat_keyness(dfm, target = "Passifs")
g3<-textplot_keyness(result_keyness,   n = 30L, labelsize = 3,   show_legend = FALSE,   show_reference = FALSE,    color = c("gold2", "gray"))+xlim(0,80)+ labs(x=NULL)
p<- plot_grid(g2, g3 ,g1,  labels = c('Détracteurs', 'Passifs', 'Promoteurs'), label_size = 12, ncol=3)
title <- ggdraw() + draw_label("NPS : Les raisons qui conduisent à la recommandation (keyness)", fontface='bold')
note <- ggdraw()+ draw_text("Les valeurs représentent le keyness des termes.\nIl mesure leur caractère distinctif par une statistique du chi²", size=8,x = 0.5, y = 0.5)
plot_grid(title, p,note, ncol=1, rel_heights=c(0.1, 1)) # rel_heights values control title margins
ggsave("NPS4.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
#  pour une comparaison deux à deux
#   pres_corpus <- corpus_subset(corpus, NPS %in% c("Détracteurs", "Promoteurs"))
plot_grid(g ,g_b,p,d, labels = c("", "", "", ""), label_size = 12,
ncol = 2, nrow = 2)
ggsave("NPS5.jpg", plot=last_plot(), width = 20, height = 20, units = "cm")
plot_grid(g ,p,d, labels = c("", "", "", ""), label_size = 12, ncol = 2, nrow = 1)
# pre processing :
toks <- tokens(corpus, remove_punct = TRUE)
cols <- textstat_collocations(toks, size = 2:4, min_count = 5) %>%filter(z>20)
toks2 <- tokens_compound(toks, pattern = cols) %>%
tokens_remove(pattern = stopwords("fr") )
dfm<-dfm(toks2)
library(seededlda)
set.seed(007)
tmod_lda <- textmodel_lda(dfm, k = 8)
#lister les mots les plus associés
terms(tmod_lda, 25)
theta<-tmod_lda$theta
View(theta)
![](Schematic-of-LDA-algorithm.png)
![modèle LDA](Schematic-of-LDA-algorithm.png)
!(modèle LDA)[Schematic-of-LDA-algorithm.png]
!(modèle LDA)[Schematic-of-LDA-algorithm.png]
!["modèle LDA"](Schematic-of-LDA-algorithm.png)
#un peu de recodage
dfm$topic <- topics(tmod_lda)
table(dfm$topic)
#on recode pour une meilleure lecture
dfm$topic2[dfm$topic=="topic1"]<-"Attente caisse"
dfm$topic2[dfm$topic=="topic2"]<-"Magasin"
dfm$topic2[dfm$topic=="topic3"]<-"Absence"
dfm$topic2[dfm$topic=="topic4"]<-"fidélité"
dfm$topic2[dfm$topic=="topic5"]<-"achat"
dfm$topic2[dfm$topic=="topic6"]<-"Compétence amabilité"
dfm$topic2[dfm$topic=="topic7"]<-"prix"
dfm$topic2[dfm$topic=="topic8"]<-"choix des plantes"
table(dfm$topic2)
#le tableau croisé
ca<- table(dfm$topic2, dfm$NPS)
prop.table(ca, 2)
#library ("FactoMineR")
#library(factoextra)
res.ca <- CA (ca, graph = FALSE)
fviz_ca_biplot (res.ca, repel = TRUE)
theta<-tmod_lda$theta
